{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edc8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\Scripts\\python.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "base_path = os.path.dirname(__file__) if '__file__' in globals() else os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(base_path, 'OpenVoice')))\n",
    "print(sys.executable)\n",
    "from OpenVoice.openvoice import se_extractor\n",
    "from OpenVoice.openvoice.api import BaseSpeakerTTS, ToneColorConverter\n",
    "import pygame as pg\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dbca3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_base='OpenVoice/checkpoints/base_speakers/EN'\n",
    "ckpt_converter = 'OpenVoice/checkpoints/converter'\n",
    "output_dir = 'OpenVoice/outputs'\n",
    "reference_speaker = 'OpenVoice/resources/demo_speaker2.mp3'\n",
    "text = \"\"\"Energy Secretary Chris Wright, who made millions in the fracking industry, commissioned the report. In a preface, he did not deny that climate change exists.\n",
    "    “Climate change is real, and it deserves attention,” he wrote. “But it is not the greatest threat facing humanity. That distinction belongs to global energy poverty.”\n",
    "    In other words, Wright sees more damage to humans from cutting back on carbon emissions.\n",
    "    That is a minority view in the scientific community, which has a much, much larger body of peer reviewed studies that raise the alarm about climate change. Most notably, the Intergovernmental Panel on Climate Change issues peer-reviewed reports with hundreds of authors from around world. The Trump administration has barred US government scientists from taking part in the next installment, due out in 2029.\"\"\"\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0422e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'OpenVoice/checkpoints/base_speakers/EN/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n",
      "Loaded checkpoint 'OpenVoice/checkpoints/converter/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n"
     ]
    }
   ],
   "source": [
    "base_speaker_tts = BaseSpeakerTTS(f'{ckpt_base}/config.json', device=device)\n",
    "base_speaker_tts.load_ckpt(f'{ckpt_base}/checkpoint.pth')\n",
    "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "source_se = torch.load(f'{ckpt_base}/en_default_se.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0716c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVoice version: v1\n",
      "[(0.0, 8.21), (9.39, 12.946), (13.262, 29.49225)]\n",
      "after vad: dur = 27.995986394557825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\functional.py:730: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\SpectralOps.cpp:880.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "target_se, audio_name = se_extractor.get_se(reference_speaker,\n",
    "                                            tone_color_converter,\n",
    "                                            target_dir='processed', \n",
    "                                            vad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43d8f7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "Energy Secretary Chris Wright, who made millions in the fracking industry,\n",
      "commissioned the report. In a preface, he did not deny that climate change exists.\n",
      "Climate change is real, and it deserves attention, he wrote. But it is not the greatest threat facing humanity.\n",
      "That distinction belongs to global energy poverty. In other words, Wright sees more damage to humans from cutting back on carbon emissions.\n",
      "That is a minority view in the scientific community, which has a much,\n",
      "much larger body of peer reviewed studies that raise the alarm about climate change.\n",
      "Most notably, the Intergovernmental Panel on Climate Change issues peer-reviewed reports with hundreds of authors from around world.\n",
      "The Trump administration has barred US government scientists from taking part in the next installment,\n",
      "due out in 2029.\n",
      " > ===========================\n",
      "ˈɛnəɹdʒi ˈsɛkɹəˌtɛɹi kɹɪs ɹaɪt, hu meɪd ˈmɪljənz ɪn ðə fɹacking* ˈɪndəstɹi,\n",
      " length:75\n",
      " length:74\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "kəˈmɪʃənd ðə ɹɪˈpɔɹt. ɪn ə ˈpɹɛfəs, hi dɪd nɑt dɪˈnaɪ ðət ˈklaɪmɪt tʃeɪndʒ ɪgˈzɪsts.\n",
      " length:84\n",
      " length:84\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ˈklaɪmɪt tʃeɪndʒ ɪz ɹiɫ, ənd ɪt dɪˈzəɹvz əˈtɛnʃən, hi ɹoʊt. bət ɪt ɪz nɑt ðə ˈgɹeɪtəst θɹɛt ˈfeɪsɪŋ juˈmænɪti.\n",
      " length:110\n",
      " length:110\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ðət dɪˈstɪŋkʃən bɪˈlɔŋz tɪ ˈgloʊbəɫ ˈɛnəɹdʒi ˈpɑvəɹti. ɪn ˈəðəɹ wəɹdz, ɹaɪt siz mɔɹ ˈdæmɪdʒ tɪ ˈjumənz fɹəm ˈkətɪŋ bæk ɔn ˈkɑɹbən ɪˈmɪʃənz.\n",
      " length:139\n",
      " length:139\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ðət ɪz ə məˈnɔɹəti vju ɪn ðə ˌsaɪənˈtɪfɪk kəmˈjunɪti, wɪtʃ həz ə mətʃ,\n",
      " length:70\n",
      " length:70\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "mətʃ ˈlɑɹdʒəɹ ˈbɑdi əv pɪɹ ɹivˈjud ˈstədiz ðət ɹeɪz ðə əˈlɑɹm əˈbaʊt ˈklaɪmɪt tʃeɪndʒ.\n",
      " length:86\n",
      " length:86\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "moʊst ˈnoʊtəbli, ðə ˌɪntəɹˌgəvəɹnˈmɛntəɫ ˈpænəɫ ɔn ˈklaɪmɪt tʃeɪndʒ ˈɪʃuz peeɹ-ɹeviewed* ɹɪˈpɔɹts wɪθ ˈhənəɹdz əv ˈɔθəɹz fɹəm əɹaʊnd wəɹɫd.\n",
      " length:139\n",
      " length:139\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ðə tɹəmp ædˌmɪnɪˈstɹeɪʃən həz bɑɹd ˈjuˈɛs ˈgəvəɹnmənt ˈsaɪəntɪsts fɹəm ˈteɪkɪŋ pɑɹt ɪn ðə nɛkst ˌɪnˈstɔlmənt,\n",
      " length:109\n",
      " length:109\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "du aʊt ɪn tˈwɛnti twenty-nine*.\n",
      " length:31\n",
      " length:31\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n"
     ]
    }
   ],
   "source": [
    "save_path = f'{output_dir}/output_en_default.wav'\n",
    "src_path = f'{output_dir}/tmp.wav'\n",
    "buffer_ouput = base_speaker_tts.tts(text, src_path, speaker=\"excited\", language='English', speed=0.9)\n",
    "encode_message = \"@Myshell\"\n",
    "tone_color_converter.convert(\n",
    "    audio_src_path=src_path, \n",
    "    src_se=source_se, \n",
    "    tgt_se=target_se, \n",
    "    output_path=save_path,\n",
    "    message=encode_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(src_path):\n",
    "    pg.init()\n",
    "    pg.mixer.init()\n",
    "    pg.mixer.music.load(src_path, \"wav\")\n",
    "    pg.mixer.music.play()\n",
    "    while pg.mixer.music.get_busy():  # Wait for playback to finish\n",
    "        pass\n",
    "play_audio(buffer_ouput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8ab3e",
   "metadata": {},
   "source": [
    "***TTS with xTTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df1230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.1 2.8.0+cu126 2.8.0+cu126\n",
      "0.25.2\n"
     ]
    }
   ],
   "source": [
    "import TTS, torch, torchaudio\n",
    "print(TTS.__version__, torch.__version__, torchaudio.__version__)\n",
    "import huggingface_hub\n",
    "print(huggingface_hub.__version__)\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xtts(\n",
       "  (gpt): GPT(\n",
       "    (conditioning_encoder): ConditioningEncoder(\n",
       "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (attn): Sequential(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (3): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (4): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (5): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "    (text_embedding): Embedding(6681, 1024)\n",
       "    (mel_embedding): Embedding(1026, 1024)\n",
       "    (gpt): GPT2Model(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-29): 30 x GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(608, 1024)\n",
       "    )\n",
       "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(404, 1024)\n",
       "    )\n",
       "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
       "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "    (conditioning_perceiver): PerceiverResampler(\n",
       "      (proj_context): Identity()\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x ModuleList(\n",
       "          (0): Attention(\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (hifigan_decoder): HifiDecoder(\n",
       "    (waveform_decoder): HifiganGenerator(\n",
       "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ParametrizedConvTranspose1d(\n",
       "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ParametrizedConvTranspose1d(\n",
       "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ParametrizedConvTranspose1d(\n",
       "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ParametrizedConvTranspose1d(\n",
       "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conds): ModuleList(\n",
       "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (speaker_encoder): ResNetSpeakerEncoder(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (torch_spec): Sequential(\n",
       "        (0): PreEmphasis()\n",
       "        (1): MelSpectrogram(\n",
       "          (spectrogram): Spectrogram()\n",
       "          (mel_scale): MelScale()\n",
       "        )\n",
       "      )\n",
       "      (attention): Sequential(\n",
       "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (4): Softmax(dim=2)\n",
       "      )\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtts_config = XttsConfig()\n",
    "xtts_config.load_json(\"xTTS/config.json\")\n",
    "\n",
    "#Initialize XTTS model\n",
    "xtts_model = Xtts.init_from_config(xtts_config)\n",
    "# xtts_model.load_checkpoint(xtts_config, checkpoint_path=\"xTTS/model.pth\",vocab_path=\"xTTS/vocab.json\", eval=True)\n",
    "with torch.serialization.safe_globals([XttsConfig]):\n",
    "    checkpoint = torch.load(\"xTTS/model.pth\", map_location=\"cpu\", weights_only=False)\n",
    "xtts_model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "import json\n",
    "\n",
    "vocab_path = 'xTTS/vocab.json'\n",
    "with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "# Create a tokenizer from vocab.json\n",
    "# This assumes vocab.json follows HuggingFace's tokenizer format\n",
    "tokenizer = Tokenizer.from_file(vocab_path)\n",
    "xtts_model.tokenizer = tokenizer\n",
    "xtts_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf549830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "c:\\Users\\minhq\\voice-assistance\\OpenVoice\\resources\\example_reference.mp3\n",
      "Xtts(\n",
      "  (gpt): GPT(\n",
      "    (conditioning_encoder): ConditioningEncoder(\n",
      "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (attn): Sequential(\n",
      "        (0): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (5): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
      "    (text_embedding): Embedding(6681, 1024)\n",
      "    (mel_embedding): Embedding(1026, 1024)\n",
      "    (gpt): GPT2Model(\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "      (h): ModuleList(\n",
      "        (0-29): 30 x GPT2Block(\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): GPT2Attention(\n",
      "            (c_attn): Conv1D()\n",
      "            (c_proj): Conv1D()\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): GPT2MLP(\n",
      "            (c_fc): Conv1D()\n",
      "            (c_proj): Conv1D()\n",
      "            (act): NewGELUActivation()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
      "      (emb): Embedding(608, 1024)\n",
      "    )\n",
      "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
      "      (emb): Embedding(404, 1024)\n",
      "    )\n",
      "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
      "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
      "    (conditioning_perceiver): PerceiverResampler(\n",
      "      (proj_context): Identity()\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ModuleList(\n",
      "          (0): Attention(\n",
      "            (attend): Attend(\n",
      "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (hifigan_decoder): HifiDecoder(\n",
      "    (waveform_decoder): HifiganGenerator(\n",
      "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (ups): ModuleList(\n",
      "        (0): ParametrizedConvTranspose1d(\n",
      "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ParametrizedConvTranspose1d(\n",
      "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ParametrizedConvTranspose1d(\n",
      "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ParametrizedConvTranspose1d(\n",
      "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (resblocks): ModuleList(\n",
      "        (0): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      (conds): ModuleList(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (speaker_encoder): ResNetSpeakerEncoder(\n",
      "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer1): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (torch_spec): Sequential(\n",
      "        (0): PreEmphasis()\n",
      "        (1): MelSpectrogram(\n",
      "          (spectrogram): Spectrogram()\n",
      "          (mel_scale): MelScale()\n",
      "        )\n",
      "      )\n",
      "      (attention): Sequential(\n",
      "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
      "        (4): Softmax(dim=2)\n",
      "      )\n",
      "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "sample_audio = \"OpenVoice/resources/example_reference.mp3\"\n",
    "print(os.path.exists(sample_audio))\n",
    "print(os.path.abspath(sample_audio))\n",
    "print(xtts_model)\n",
    "import traceback\n",
    "def process_and_play(xtts_model, prompt, audio_file_pth): \n",
    "    try:\n",
    "        # Use XTTS to synthesize speech\n",
    "        outputs = xtts_model.synthesize(\n",
    "            prompt,\n",
    "            xtts_config,\n",
    "            speaker_wav=audio_file_pth, # Pass the file path directly\n",
    "            gpt_cond_len=24,\n",
    "            temperature=0.6,\n",
    "            language='en',\n",
    "        )\n",
    "        synthesized_audio = outputs['wav']\n",
    "        print(synthesized_audio)\n",
    "# Save the synthesized audio to the output path \n",
    "        src_path = f'{output_dir}/output.wav' \n",
    "        sample_rate = xtts_config.audio.sample_rate \n",
    "        sf.write(src_path, synthesized_audio, sample_rate)\n",
    "        print(\"Audio generated successfully.\")\n",
    "        play_audio(src_path)\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        print (f\"Error during audio generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b64a2e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\minhq\\AppData\\Local\\Temp\\ipykernel_20208\\1801340675.py\", line 10, in process_and_play\n",
      "    outputs = xtts_model.synthesize(\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 392, in synthesize\n",
      "    return self.inference_with_config(text, config, ref_audio_path=speaker_wav, language=language, **kwargs)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 414, in inference_with_config\n",
      "    return self.full_inference(text, ref_audio_path, language, **settings)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 483, in full_inference\n",
      "    return self.inference(\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 527, in inference\n",
      "    text_tokens = torch.IntTensor(self.tokenizer.encode(sent, lang=language)).unsqueeze(0).to(self.device)\n",
      "TypeError: Tokenizer.encode() got an unexpected keyword argument 'lang'\n",
      "\n",
      "Error during audio generation: Tokenizer.encode() got an unexpected keyword argument 'lang'\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Hello, I am a ML developer\"\n",
    "# Convert to WAV if needed\n",
    "if sample_audio.endswith(\".mp3\"):\n",
    "    wav_path = sample_audio.replace(\".mp3\", \".wav\")\n",
    "    data, sr = sf.read(sample_audio)\n",
    "    sf.write(wav_path, data, sr)\n",
    "    speaker_path = wav_path\n",
    "process_and_play(xtts_model=xtts_model, prompt=text2, audio_file_pth=sample_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1899c",
   "metadata": {},
   "source": [
    "***Faster whisper***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "model_size = \"small.en\"\n",
    "local_dir = \"STT-model\"\n",
    "import os\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)\n",
    "    whisper_model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", download_root=local_dir)\n",
    "else:\n",
    "    whisper_model = WhisperModel('STT-model\\models--guillaumekln--faster-whisper-small.en\\snapshots\\model', device=\"cpu\", compute_type=\"int8\", local_files_only=True)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6147fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    start_time = time.time()\n",
    "    segments, info = whisper_model.transcribe(audio_path, beam_size=5)\n",
    "    transcription = \"\"\n",
    "    for segment in segments:\n",
    "        transcription += segment.text + \" \"\n",
    "    end_time = time.time()\n",
    "    inference_time = (end_time-start_time)\n",
    "    print(f\"Inference time: {inference_time}\")\n",
    "    return transcription.strip()\n",
    "\n",
    "path = \"OpenVoice/resources/example_reference.wav\"\n",
    "output = transcribe_audio(path)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a785ff2",
   "metadata": {},
   "source": [
    "***So the TTS model running oke, now we test the LLM model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fbc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad21ba",
   "metadata": {},
   "source": [
    "***Testing with model MiniLM-L6 by Sentence-tranformers, and it's used just for sentence encoding only***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e298dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 8.6439e-02,  1.0276e-01,  5.3946e-03,  2.0444e-03, -9.9633e-03,\n",
      "          2.5386e-02,  4.9288e-02, -3.0627e-02,  6.8725e-02,  1.0137e-02,\n",
      "          7.7540e-02, -9.0081e-02,  6.1062e-03, -5.6990e-02,  1.4171e-02,\n",
      "          2.8049e-02, -8.6846e-02,  7.6440e-02, -1.0349e-01, -6.7744e-02,\n",
      "          6.9995e-02,  8.4425e-02, -7.2491e-03,  1.0477e-02,  1.3402e-02,\n",
      "          6.7758e-02, -9.4209e-02, -3.7169e-02,  5.2262e-02, -3.1085e-02,\n",
      "         -9.6341e-02,  1.5772e-02,  2.5787e-02,  7.8525e-02,  7.8995e-02,\n",
      "          1.9152e-02,  1.6436e-02,  3.1009e-03,  3.8131e-02,  2.3709e-02,\n",
      "          1.0539e-02, -4.4064e-02,  4.4174e-02, -2.5873e-02,  6.1538e-02,\n",
      "         -4.0543e-02, -8.6414e-02,  3.1972e-02, -8.9067e-04, -2.4444e-02,\n",
      "         -9.1972e-02,  2.3394e-02, -8.3029e-02,  4.4151e-02, -2.4969e-02,\n",
      "          6.2302e-02, -1.3036e-03,  7.5140e-02,  2.4638e-02, -6.4724e-02,\n",
      "         -1.1773e-01,  3.8339e-02, -9.1177e-02,  6.3545e-02,  7.6274e-02,\n",
      "         -8.8024e-02,  9.5456e-03, -4.6972e-02, -8.4174e-02,  3.8882e-02,\n",
      "         -1.1439e-01,  6.2886e-03, -3.4936e-02,  2.3975e-02, -3.3132e-02,\n",
      "         -1.5724e-02, -3.7896e-02, -8.8125e-03,  7.0612e-02,  3.2807e-02,\n",
      "          2.0367e-03, -1.1228e-01,  6.7972e-03,  1.2277e-02,  3.3530e-02,\n",
      "         -1.3620e-02, -2.2549e-02, -2.2523e-02, -2.0319e-02,  5.0430e-02,\n",
      "         -7.4865e-02, -8.2282e-02,  7.6596e-02,  4.9339e-02, -3.7555e-02,\n",
      "          1.4463e-02, -5.7246e-02, -1.7995e-02,  1.0970e-01,  1.1946e-01,\n",
      "          8.0926e-04,  6.1706e-02,  3.2632e-02, -1.3078e-01, -1.4864e-01,\n",
      "         -6.1623e-02,  4.3389e-02,  2.6713e-02,  1.3979e-02, -3.9400e-02,\n",
      "         -2.5271e-02,  3.8774e-03,  3.5866e-02, -6.1542e-02,  3.7666e-02,\n",
      "          2.6757e-02, -3.8266e-02, -3.5479e-02, -2.3923e-02,  8.6798e-02,\n",
      "         -1.8406e-02,  7.7104e-02,  1.3986e-03,  7.0038e-02, -4.7788e-02,\n",
      "         -7.8982e-02,  5.1081e-02, -2.9987e-33, -3.9165e-02, -2.5621e-03,\n",
      "          1.6521e-02,  9.4894e-03, -5.6622e-02,  6.5778e-02, -4.7700e-02,\n",
      "          1.1166e-02, -5.7356e-02, -9.1626e-03, -2.1752e-02, -5.5953e-02,\n",
      "         -1.1142e-02,  9.3279e-02,  1.6677e-02, -1.3672e-02,  4.3439e-02,\n",
      "          1.8724e-03,  7.2995e-03,  5.1633e-02,  4.8061e-02,  1.3534e-01,\n",
      "         -1.7174e-02, -1.2970e-02, -7.5011e-02,  2.6111e-02,  2.6980e-02,\n",
      "          7.8307e-04, -4.8727e-02,  1.1784e-02, -4.5958e-02, -4.8321e-02,\n",
      "         -1.9567e-02,  1.9389e-02,  1.9881e-02,  1.6743e-02,  9.8780e-02,\n",
      "         -2.7409e-02,  2.3481e-02,  3.7023e-03, -6.1451e-02, -1.2123e-03,\n",
      "         -9.5047e-03,  9.2515e-03,  2.3844e-02,  8.6123e-02,  2.2679e-02,\n",
      "          5.4515e-04,  3.4713e-02,  6.2546e-03, -6.9278e-03,  3.9240e-02,\n",
      "          1.1567e-02,  3.2628e-02,  6.2216e-02,  2.7611e-02,  1.8688e-02,\n",
      "          3.5581e-02,  4.1180e-02,  1.5478e-02,  4.2269e-02,  3.8225e-02,\n",
      "          1.0031e-02, -2.8325e-02,  4.4705e-02, -4.1046e-02, -4.5054e-03,\n",
      "         -5.4473e-02,  2.6232e-02,  1.7986e-02, -1.2312e-01, -4.6695e-02,\n",
      "         -1.3591e-02,  6.4671e-02,  3.5735e-03, -1.2223e-02, -1.7938e-02,\n",
      "         -2.5550e-02,  2.3722e-02,  4.0867e-03, -6.5148e-02,  4.4365e-02,\n",
      "          4.6860e-02, -3.2517e-02,  4.0227e-03, -3.9760e-03,  1.1194e-02,\n",
      "         -9.9560e-02,  3.3317e-02,  8.0106e-02,  9.4269e-02, -6.3829e-02,\n",
      "          3.2315e-02, -5.1355e-02, -7.4987e-03,  5.3005e-34, -4.1320e-02,\n",
      "          9.4965e-02, -1.0640e-01,  4.9659e-02, -3.4191e-02, -3.1675e-02,\n",
      "         -1.7156e-02,  1.7010e-03,  5.7976e-02, -1.2177e-03, -1.6854e-02,\n",
      "         -5.1691e-02,  5.5300e-02, -3.4265e-02,  3.0818e-02, -3.1048e-02,\n",
      "          9.2753e-02,  3.7266e-02, -2.3740e-02,  4.4589e-02,  1.4615e-02,\n",
      "          1.1624e-01, -5.0011e-02,  3.8872e-02,  4.2474e-03,  2.5698e-02,\n",
      "          3.2724e-02,  4.2991e-02, -1.3614e-02,  2.5612e-02,  1.0626e-02,\n",
      "         -8.4686e-02, -9.5298e-02,  1.0840e-01, -7.5160e-02, -1.3777e-02,\n",
      "          6.3734e-02, -4.4967e-03, -3.2532e-02,  6.2361e-02,  3.4805e-02,\n",
      "         -3.5492e-02, -2.0022e-02,  3.6661e-02, -2.4884e-02,  1.0182e-02,\n",
      "         -7.0123e-02, -4.3195e-02,  2.9533e-02, -2.9488e-04, -3.4539e-02,\n",
      "          1.4668e-02, -9.8397e-02, -4.7049e-02, -8.8550e-03, -8.8991e-02,\n",
      "          3.5100e-02, -1.2960e-01, -4.9887e-02, -6.1205e-02, -5.9780e-02,\n",
      "          9.4632e-03,  4.9122e-02, -7.7503e-02,  8.0973e-02, -4.7926e-02,\n",
      "          2.3438e-03,  7.5703e-02, -2.4018e-02, -1.5255e-02,  4.8674e-02,\n",
      "         -3.8597e-02, -7.0483e-02, -1.2035e-02, -3.8879e-02, -7.7602e-02,\n",
      "         -1.0724e-02,  1.0419e-02, -2.1375e-02, -9.1739e-02, -1.1134e-02,\n",
      "         -2.9607e-02,  2.4646e-02,  4.6571e-03, -1.6345e-02, -3.9522e-02,\n",
      "          7.7337e-02, -2.8473e-02, -3.6994e-03,  8.2767e-02, -1.1041e-02,\n",
      "          3.1398e-02,  5.3509e-02,  5.7515e-02, -3.1762e-02, -1.5291e-08,\n",
      "         -7.9966e-02, -4.7680e-02, -8.5979e-02,  5.6962e-02, -4.0887e-02,\n",
      "          2.2383e-02, -4.6445e-03, -3.8013e-02, -3.1067e-02, -1.0728e-02,\n",
      "          1.9770e-02,  7.7700e-03, -6.0948e-03, -3.8638e-02,  2.8027e-02,\n",
      "          6.7814e-02, -2.3535e-02,  3.2175e-02,  8.0254e-03, -2.3911e-02,\n",
      "         -1.2200e-03,  3.1460e-02, -5.2492e-02, -8.0681e-03,  3.1477e-03,\n",
      "          5.1150e-02, -4.4410e-02,  6.3601e-02,  3.8508e-02,  3.3043e-02,\n",
      "         -4.1873e-03,  4.9559e-02, -5.6961e-02, -6.4971e-03, -2.4979e-02,\n",
      "         -1.6087e-02,  6.6229e-02, -2.0631e-02,  1.0805e-01,  1.6855e-02,\n",
      "          1.4381e-02, -1.3213e-02, -1.2939e-01,  6.9522e-02, -5.5577e-02,\n",
      "         -6.7541e-02, -5.4582e-03, -6.1360e-03,  3.9084e-02, -6.2878e-02,\n",
      "          3.7406e-02, -1.1657e-02,  1.2915e-02, -5.5250e-02,  5.1608e-02,\n",
      "         -4.3084e-03,  5.8025e-02,  1.8694e-02,  2.2781e-02,  3.2167e-02,\n",
      "          5.3798e-02,  7.0285e-02,  7.4931e-02, -8.4177e-02]])\n",
      "Original sentence: each sentence is converted\n"
     ]
    }
   ],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "cache_dir = 'MiniLM-L6'\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = f.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "# the sentence embeddings return a 2D dimentional array\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n",
    "\n",
    "# decoded_text  = tokenizer.decode(encoded_input['input_ids'][0], skip_special_tokens=True)\n",
    "# print(f\"Original sentence: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9fe11",
   "metadata": {},
   "source": [
    "***Now we test the LLM model***. We can run different models with different sizes, for example 6B, or larger liek 20B, or 100B parameters. But everything must start with \"checking device\" first, choosing what models to run depends on the hardware configuration. Some PC only has CPU supported while others have strong GPU to run heavy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda0270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     23\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m     24\u001b[0m     load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m     llm_int8_enable_fp32_cpu_offload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Load the model with 8-bit quantization and mixed precision\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./offload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Enable gradient checkpointing\u001b[39;00m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39mgradient_checkpointing_enable()\n",
      "File \u001b[1;32mc:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    495\u001b[0m     )\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\transformers\\modeling_utils.py:2277\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m load_in_4bit:\n\u001b[0;32m   2276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[1;32m-> 2277\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2278\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m pip install bitsandbytes` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2281\u001b[0m         )\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2284\u001b[0m         \u001b[38;5;66;03m# We force the `dtype` to be float16, this is a requirement from `bitsandbytes`\u001b[39;00m\n\u001b[0;32m   2285\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2286\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverriding torch_dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with `torch_dtype=torch.float16` due to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2287\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2288\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2289\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch_dtype=torch.float16 to remove this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2290\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*copying from a non-meta parameter.*\")\n",
    "model_name = \"facebook/opt-2.7B\"\n",
    "cache_dir = \"./optimized-opt-2.7B-8bit\"\n",
    "local_dir = \"./optimized-opt-2.7B-8bit/models--facebook--opt-2.7B/snapshots/905a4b602cda5c501f1b3a2650a4152680238254\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# Initialize model with empty weights to manage device map efficiently\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "    # tie the model weights to prevent memory overhead\n",
    "    model.tie_weights()\n",
    "\n",
    "# Infer device map to manage model layers between GPU and CPU\n",
    "device_map = infer_auto_device_map(model, max_memory={0: \"4GiB\", \"cpu\": \"6GiB\"})\n",
    "\n",
    "# configure quantization using BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "\n",
    "# Load the model with 8-bit quantization and mixed precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=cache_dir,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    offload_folder=\"./offload\",\n",
    "    torch_dtype=torch.float16,\n",
    "    offload_state_dict=True\n",
    ")\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "def generate_text(prompt, max_length=500):\n",
    "    # Move inputs to the appropriate device (CPU or GPU)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Generate text using the optimized model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=max_length,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "    # Decode the outputs and return the generated text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6107d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
