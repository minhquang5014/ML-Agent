{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edc8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\Scripts\\python.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "base_path = os.path.dirname(__file__) if '__file__' in globals() else os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(base_path, 'OpenVoice')))\n",
    "print(sys.executable)\n",
    "from OpenVoice.openvoice import se_extractor\n",
    "from OpenVoice.openvoice.api import BaseSpeakerTTS, ToneColorConverter\n",
    "import pygame as pg\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dbca3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_base='OpenVoice/checkpoints/base_speakers/EN'\n",
    "ckpt_converter = 'OpenVoice/checkpoints/converter'\n",
    "output_dir = 'OpenVoice/outputs'\n",
    "reference_speaker = 'OpenVoice/resources/demo_speaker2.mp3'\n",
    "text = \"\"\"Energy Secretary Chris Wright, who made millions in the fracking industry, commissioned the report. In a preface, he did not deny that climate change exists.\n",
    "    “Climate change is real, and it deserves attention,” he wrote. “But it is not the greatest threat facing humanity. That distinction belongs to global energy poverty.”\n",
    "    In other words, Wright sees more damage to humans from cutting back on carbon emissions.\n",
    "    That is a minority view in the scientific community, which has a much, much larger body of peer reviewed studies that raise the alarm about climate change. Most notably, the Intergovernmental Panel on Climate Change issues peer-reviewed reports with hundreds of authors from around world. The Trump administration has barred US government scientists from taking part in the next installment, due out in 2029.\"\"\"\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0422e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'OpenVoice/checkpoints/base_speakers/EN/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n",
      "Loaded checkpoint 'OpenVoice/checkpoints/converter/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n"
     ]
    }
   ],
   "source": [
    "base_speaker_tts = BaseSpeakerTTS(f'{ckpt_base}/config.json', device=device)\n",
    "base_speaker_tts.load_ckpt(f'{ckpt_base}/checkpoint.pth')\n",
    "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "source_se = torch.load(f'{ckpt_base}/en_default_se.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0716c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVoice version: v1\n",
      "[(0.0, 8.21), (9.39, 12.946), (13.262, 29.49225)]\n",
      "after vad: dur = 27.995986394557825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\functional.py:730: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\SpectralOps.cpp:880.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "target_se, audio_name = se_extractor.get_se(reference_speaker,\n",
    "                                            tone_color_converter,\n",
    "                                            target_dir='processed', \n",
    "                                            vad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43d8f7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "Energy Secretary Chris Wright, who made millions in the fracking industry,\n",
      "commissioned the report. In a preface, he did not deny that climate change exists.\n",
      "Climate change is real, and it deserves attention, he wrote. But it is not the greatest threat facing humanity.\n",
      "That distinction belongs to global energy poverty. In other words, Wright sees more damage to humans from cutting back on carbon emissions.\n",
      "That is a minority view in the scientific community, which has a much,\n",
      "much larger body of peer reviewed studies that raise the alarm about climate change.\n",
      "Most notably, the Intergovernmental Panel on Climate Change issues peer-reviewed reports with hundreds of authors from around world.\n",
      "The Trump administration has barred US government scientists from taking part in the next installment,\n",
      "due out in 2029.\n",
      " > ===========================\n",
      "ˈɛnəɹdʒi ˈsɛkɹəˌtɛɹi kɹɪs ɹaɪt, hu meɪd ˈmɪljənz ɪn ðə fɹacking* ˈɪndəstɹi,\n",
      " length:75\n",
      " length:74\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "kəˈmɪʃənd ðə ɹɪˈpɔɹt. ɪn ə ˈpɹɛfəs, hi dɪd nɑt dɪˈnaɪ ðət ˈklaɪmɪt tʃeɪndʒ ɪgˈzɪsts.\n",
      " length:84\n",
      " length:84\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ˈklaɪmɪt tʃeɪndʒ ɪz ɹiɫ, ənd ɪt dɪˈzəɹvz əˈtɛnʃən, hi ɹoʊt. bət ɪt ɪz nɑt ðə ˈgɹeɪtəst θɹɛt ˈfeɪsɪŋ juˈmænɪti.\n",
      " length:110\n",
      " length:110\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ðət dɪˈstɪŋkʃən bɪˈlɔŋz tɪ ˈgloʊbəɫ ˈɛnəɹdʒi ˈpɑvəɹti. ɪn ˈəðəɹ wəɹdz, ɹaɪt siz mɔɹ ˈdæmɪdʒ tɪ ˈjumənz fɹəm ˈkətɪŋ bæk ɔn ˈkɑɹbən ɪˈmɪʃənz.\n",
      " length:139\n",
      " length:139\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ðət ɪz ə məˈnɔɹəti vju ɪn ðə ˌsaɪənˈtɪfɪk kəmˈjunɪti, wɪtʃ həz ə mətʃ,\n",
      " length:70\n",
      " length:70\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "mətʃ ˈlɑɹdʒəɹ ˈbɑdi əv pɪɹ ɹivˈjud ˈstədiz ðət ɹeɪz ðə əˈlɑɹm əˈbaʊt ˈklaɪmɪt tʃeɪndʒ.\n",
      " length:86\n",
      " length:86\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "moʊst ˈnoʊtəbli, ðə ˌɪntəɹˌgəvəɹnˈmɛntəɫ ˈpænəɫ ɔn ˈklaɪmɪt tʃeɪndʒ ˈɪʃuz peeɹ-ɹeviewed* ɹɪˈpɔɹts wɪθ ˈhənəɹdz əv ˈɔθəɹz fɹəm əɹaʊnd wəɹɫd.\n",
      " length:139\n",
      " length:139\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "ðə tɹəmp ædˌmɪnɪˈstɹeɪʃən həz bɑɹd ˈjuˈɛs ˈgəvəɹnmənt ˈsaɪəntɪsts fɹəm ˈteɪkɪŋ pɑɹt ɪn ðə nɛkst ˌɪnˈstɔlmənt,\n",
      " length:109\n",
      " length:109\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n",
      "du aʊt ɪn tˈwɛnti twenty-nine*.\n",
      " length:31\n",
      " length:31\n",
      "Voice that we can use {'default': 1, 'whispering': 2, 'shouting': 3, 'excited': 4, 'cheerful': 5, 'terrified': 6, 'angry': 7, 'sad': 8, 'friendly': 9}\n"
     ]
    }
   ],
   "source": [
    "save_path = f'{output_dir}/output_en_default.wav'\n",
    "src_path = f'{output_dir}/tmp.wav'\n",
    "buffer_ouput = base_speaker_tts.tts(text, src_path, speaker=\"excited\", language='English', speed=0.9)\n",
    "encode_message = \"@Myshell\"\n",
    "tone_color_converter.convert(\n",
    "    audio_src_path=src_path, \n",
    "    src_se=source_se, \n",
    "    tgt_se=target_se, \n",
    "    output_path=save_path,\n",
    "    message=encode_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(src_path):\n",
    "    pg.init()\n",
    "    pg.mixer.init()\n",
    "    pg.mixer.music.load(src_path, \"wav\")\n",
    "    pg.mixer.music.play()\n",
    "    while pg.mixer.music.get_busy():  # Wait for playback to finish\n",
    "        pass\n",
    "play_audio(buffer_ouput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8ab3e",
   "metadata": {},
   "source": [
    "***TTS with xTTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df1230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.1 2.8.0+cu126 2.8.0+cu126\n",
      "0.25.2\n"
     ]
    }
   ],
   "source": [
    "import TTS, torch, torchaudio\n",
    "print(TTS.__version__, torch.__version__, torchaudio.__version__)\n",
    "import huggingface_hub\n",
    "print(huggingface_hub.__version__)\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928112d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xtts(\n",
       "  (gpt): GPT(\n",
       "    (conditioning_encoder): ConditioningEncoder(\n",
       "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (attn): Sequential(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (3): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (4): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (5): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "    (text_embedding): Embedding(6681, 1024)\n",
       "    (mel_embedding): Embedding(1026, 1024)\n",
       "    (gpt): GPT2Model(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-29): 30 x GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(608, 1024)\n",
       "    )\n",
       "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(404, 1024)\n",
       "    )\n",
       "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
       "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "    (conditioning_perceiver): PerceiverResampler(\n",
       "      (proj_context): Identity()\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x ModuleList(\n",
       "          (0): Attention(\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (hifigan_decoder): HifiDecoder(\n",
       "    (waveform_decoder): HifiganGenerator(\n",
       "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ParametrizedConvTranspose1d(\n",
       "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ParametrizedConvTranspose1d(\n",
       "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ParametrizedConvTranspose1d(\n",
       "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ParametrizedConvTranspose1d(\n",
       "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conds): ModuleList(\n",
       "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (speaker_encoder): ResNetSpeakerEncoder(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (torch_spec): Sequential(\n",
       "        (0): PreEmphasis()\n",
       "        (1): MelSpectrogram(\n",
       "          (spectrogram): Spectrogram()\n",
       "          (mel_scale): MelScale()\n",
       "        )\n",
       "      )\n",
       "      (attention): Sequential(\n",
       "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (4): Softmax(dim=2)\n",
       "      )\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtts_config = XttsConfig()\n",
    "xtts_config.load_json(\"xTTS/config.json\")\n",
    "\n",
    "#Initialize XTTS model\n",
    "xtts_model = Xtts.init_from_config(xtts_config)\n",
    "# xtts_model.load_checkpoint(xtts_config, checkpoint_path=\"xTTS/model.pth\",vocab_path=\"xTTS/vocab.json\", eval=True)\n",
    "with torch.serialization.safe_globals([XttsConfig]):\n",
    "    checkpoint = torch.load(\"xTTS/model.pth\", map_location=\"cpu\", weights_only=False)\n",
    "xtts_model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "import json\n",
    "\n",
    "vocab_path = 'xTTS/vocab.json'\n",
    "with open(vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "# Create a tokenizer from vocab.json\n",
    "# This assumes vocab.json follows HuggingFace's tokenizer format\n",
    "tokenizer = Tokenizer.from_file(vocab_path)\n",
    "xtts_model.tokenizer = tokenizer\n",
    "xtts_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf549830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "c:\\Users\\minhq\\voice-assistance\\OpenVoice\\resources\\example_reference.mp3\n",
      "Xtts(\n",
      "  (gpt): GPT(\n",
      "    (conditioning_encoder): ConditioningEncoder(\n",
      "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (attn): Sequential(\n",
      "        (0): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (2): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (3): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (4): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (5): AttentionBlock(\n",
      "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
      "          (attention): QKVAttention()\n",
      "          (x_proj): Identity()\n",
      "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
      "    (text_embedding): Embedding(6681, 1024)\n",
      "    (mel_embedding): Embedding(1026, 1024)\n",
      "    (gpt): GPT2Model(\n",
      "      (drop): Dropout(p=0.1, inplace=False)\n",
      "      (h): ModuleList(\n",
      "        (0-29): 30 x GPT2Block(\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): GPT2Attention(\n",
      "            (c_attn): Conv1D()\n",
      "            (c_proj): Conv1D()\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): GPT2MLP(\n",
      "            (c_fc): Conv1D()\n",
      "            (c_proj): Conv1D()\n",
      "            (act): NewGELUActivation()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
      "      (emb): Embedding(608, 1024)\n",
      "    )\n",
      "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
      "      (emb): Embedding(404, 1024)\n",
      "    )\n",
      "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
      "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
      "    (conditioning_perceiver): PerceiverResampler(\n",
      "      (proj_context): Identity()\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x ModuleList(\n",
      "          (0): Attention(\n",
      "            (attend): Attend(\n",
      "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
      "            (1): GEGLU()\n",
      "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (hifigan_decoder): HifiDecoder(\n",
      "    (waveform_decoder): HifiganGenerator(\n",
      "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (ups): ModuleList(\n",
      "        (0): ParametrizedConvTranspose1d(\n",
      "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ParametrizedConvTranspose1d(\n",
      "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ParametrizedConvTranspose1d(\n",
      "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ParametrizedConvTranspose1d(\n",
      "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (resblocks): ModuleList(\n",
      "        (0): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): ResBlock1(\n",
      "          (convs1): ModuleList(\n",
      "            (0): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (convs2): ModuleList(\n",
      "            (0-2): 3 x ParametrizedConv1d(\n",
      "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
      "              (parametrizations): ModuleDict(\n",
      "                (weight): ParametrizationList(\n",
      "                  (0): _WeightNorm()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      (conds): ModuleList(\n",
      "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
      "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (speaker_encoder): ResNetSpeakerEncoder(\n",
      "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer1): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): SEBasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SEBasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SEBasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (se): SELayer(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (torch_spec): Sequential(\n",
      "        (0): PreEmphasis()\n",
      "        (1): MelSpectrogram(\n",
      "          (spectrogram): Spectrogram()\n",
      "          (mel_scale): MelScale()\n",
      "        )\n",
      "      )\n",
      "      (attention): Sequential(\n",
      "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
      "        (4): Softmax(dim=2)\n",
      "      )\n",
      "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "sample_audio = \"OpenVoice/resources/example_reference.mp3\"\n",
    "print(os.path.exists(sample_audio))\n",
    "print(os.path.abspath(sample_audio))\n",
    "print(xtts_model)\n",
    "import traceback\n",
    "def process_and_play(xtts_model, prompt, audio_file_pth): \n",
    "    try:\n",
    "        # Use XTTS to synthesize speech\n",
    "        outputs = xtts_model.synthesize(\n",
    "            prompt,\n",
    "            xtts_config,\n",
    "            speaker_wav=audio_file_pth, # Pass the file path directly\n",
    "            gpt_cond_len=24,\n",
    "            temperature=0.6,\n",
    "            language='en',\n",
    "        )\n",
    "        synthesized_audio = outputs['wav']\n",
    "        print(synthesized_audio)\n",
    "# Save the synthesized audio to the output path \n",
    "        src_path = f'{output_dir}/output.wav' \n",
    "        sample_rate = xtts_config.audio.sample_rate \n",
    "        sf.write(src_path, synthesized_audio, sample_rate)\n",
    "        print(\"Audio generated successfully.\")\n",
    "        play_audio(src_path)\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        print (f\"Error during audio generation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b64a2e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\minhq\\AppData\\Local\\Temp\\ipykernel_20208\\1801340675.py\", line 10, in process_and_play\n",
      "    outputs = xtts_model.synthesize(\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 392, in synthesize\n",
      "    return self.inference_with_config(text, config, ref_audio_path=speaker_wav, language=language, **kwargs)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 414, in inference_with_config\n",
      "    return self.full_inference(text, ref_audio_path, language, **settings)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 483, in full_inference\n",
      "    return self.inference(\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 120, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\TTS\\tts\\models\\xtts.py\", line 527, in inference\n",
      "    text_tokens = torch.IntTensor(self.tokenizer.encode(sent, lang=language)).unsqueeze(0).to(self.device)\n",
      "TypeError: Tokenizer.encode() got an unexpected keyword argument 'lang'\n",
      "\n",
      "Error during audio generation: Tokenizer.encode() got an unexpected keyword argument 'lang'\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Hello, I am a ML developer\"\n",
    "# Convert to WAV if needed\n",
    "if sample_audio.endswith(\".mp3\"):\n",
    "    wav_path = sample_audio.replace(\".mp3\", \".wav\")\n",
    "    data, sr = sf.read(sample_audio)\n",
    "    sf.write(wav_path, data, sr)\n",
    "    speaker_path = wav_path\n",
    "process_and_play(xtts_model=xtts_model, prompt=text2, audio_file_pth=sample_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1899c",
   "metadata": {},
   "source": [
    "***Faster whisper***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "model_size = \"small.en\"\n",
    "local_dir = \"STT-model\"\n",
    "import os\n",
    "if not os.path.exists(local_dir):\n",
    "    os.mkdir(local_dir)\n",
    "    whisper_model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", download_root=local_dir)\n",
    "else:\n",
    "    whisper_model = WhisperModel('STT-model\\models--guillaumekln--faster-whisper-small.en\\snapshots\\model', device=\"cpu\", compute_type=\"int8\", local_files_only=True)\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6147fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def transcribe_audio(audio_path):\n",
    "    start_time = time.time()\n",
    "    segments, info = whisper_model.transcribe(audio_path, beam_size=5)\n",
    "    transcription = \"\"\n",
    "    for segment in segments:\n",
    "        transcription += segment.text + \" \"\n",
    "    end_time = time.time()\n",
    "    inference_time = (end_time-start_time)\n",
    "    print(f\"Inference time: {inference_time}\")\n",
    "    return transcription.strip()\n",
    "\n",
    "path = \"OpenVoice/resources/example_reference.wav\"\n",
    "output = transcribe_audio(path)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a785ff2",
   "metadata": {},
   "source": [
    "***So the TTS model running oke, now we test the LLM model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fbc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\voice-assistance\\xtts_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad21ba",
   "metadata": {},
   "source": [
    "***Testing with model MiniLM-L6 by Sentence-tranformers, and it's used just for sentence encoding only***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e298dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 8.6439e-02,  1.0276e-01,  5.3946e-03,  2.0444e-03, -9.9633e-03,\n",
      "          2.5386e-02,  4.9288e-02, -3.0627e-02,  6.8725e-02,  1.0137e-02,\n",
      "          7.7540e-02, -9.0081e-02,  6.1062e-03, -5.6990e-02,  1.4171e-02,\n",
      "          2.8049e-02, -8.6846e-02,  7.6440e-02, -1.0349e-01, -6.7744e-02,\n",
      "          6.9995e-02,  8.4425e-02, -7.2491e-03,  1.0477e-02,  1.3402e-02,\n",
      "          6.7758e-02, -9.4209e-02, -3.7169e-02,  5.2262e-02, -3.1085e-02,\n",
      "         -9.6341e-02,  1.5772e-02,  2.5787e-02,  7.8525e-02,  7.8995e-02,\n",
      "          1.9152e-02,  1.6436e-02,  3.1009e-03,  3.8131e-02,  2.3709e-02,\n",
      "          1.0539e-02, -4.4064e-02,  4.4174e-02, -2.5873e-02,  6.1538e-02,\n",
      "         -4.0543e-02, -8.6414e-02,  3.1972e-02, -8.9067e-04, -2.4444e-02,\n",
      "         -9.1972e-02,  2.3394e-02, -8.3029e-02,  4.4151e-02, -2.4969e-02,\n",
      "          6.2302e-02, -1.3036e-03,  7.5140e-02,  2.4638e-02, -6.4724e-02,\n",
      "         -1.1773e-01,  3.8339e-02, -9.1177e-02,  6.3545e-02,  7.6274e-02,\n",
      "         -8.8024e-02,  9.5456e-03, -4.6972e-02, -8.4174e-02,  3.8882e-02,\n",
      "         -1.1439e-01,  6.2886e-03, -3.4936e-02,  2.3975e-02, -3.3132e-02,\n",
      "         -1.5724e-02, -3.7896e-02, -8.8125e-03,  7.0612e-02,  3.2807e-02,\n",
      "          2.0367e-03, -1.1228e-01,  6.7972e-03,  1.2277e-02,  3.3530e-02,\n",
      "         -1.3620e-02, -2.2549e-02, -2.2523e-02, -2.0319e-02,  5.0430e-02,\n",
      "         -7.4865e-02, -8.2282e-02,  7.6596e-02,  4.9339e-02, -3.7555e-02,\n",
      "          1.4463e-02, -5.7246e-02, -1.7995e-02,  1.0970e-01,  1.1946e-01,\n",
      "          8.0926e-04,  6.1706e-02,  3.2632e-02, -1.3078e-01, -1.4864e-01,\n",
      "         -6.1623e-02,  4.3389e-02,  2.6713e-02,  1.3979e-02, -3.9400e-02,\n",
      "         -2.5271e-02,  3.8774e-03,  3.5866e-02, -6.1542e-02,  3.7666e-02,\n",
      "          2.6757e-02, -3.8266e-02, -3.5479e-02, -2.3923e-02,  8.6798e-02,\n",
      "         -1.8406e-02,  7.7104e-02,  1.3986e-03,  7.0038e-02, -4.7788e-02,\n",
      "         -7.8982e-02,  5.1081e-02, -2.9987e-33, -3.9165e-02, -2.5621e-03,\n",
      "          1.6521e-02,  9.4894e-03, -5.6622e-02,  6.5778e-02, -4.7700e-02,\n",
      "          1.1166e-02, -5.7356e-02, -9.1626e-03, -2.1752e-02, -5.5953e-02,\n",
      "         -1.1142e-02,  9.3279e-02,  1.6677e-02, -1.3672e-02,  4.3439e-02,\n",
      "          1.8724e-03,  7.2995e-03,  5.1633e-02,  4.8061e-02,  1.3534e-01,\n",
      "         -1.7174e-02, -1.2970e-02, -7.5011e-02,  2.6111e-02,  2.6980e-02,\n",
      "          7.8307e-04, -4.8727e-02,  1.1784e-02, -4.5958e-02, -4.8321e-02,\n",
      "         -1.9567e-02,  1.9389e-02,  1.9881e-02,  1.6743e-02,  9.8780e-02,\n",
      "         -2.7409e-02,  2.3481e-02,  3.7023e-03, -6.1451e-02, -1.2123e-03,\n",
      "         -9.5047e-03,  9.2515e-03,  2.3844e-02,  8.6123e-02,  2.2679e-02,\n",
      "          5.4515e-04,  3.4713e-02,  6.2546e-03, -6.9278e-03,  3.9240e-02,\n",
      "          1.1567e-02,  3.2628e-02,  6.2216e-02,  2.7611e-02,  1.8688e-02,\n",
      "          3.5581e-02,  4.1180e-02,  1.5478e-02,  4.2269e-02,  3.8225e-02,\n",
      "          1.0031e-02, -2.8325e-02,  4.4705e-02, -4.1046e-02, -4.5054e-03,\n",
      "         -5.4473e-02,  2.6232e-02,  1.7986e-02, -1.2312e-01, -4.6695e-02,\n",
      "         -1.3591e-02,  6.4671e-02,  3.5735e-03, -1.2223e-02, -1.7938e-02,\n",
      "         -2.5550e-02,  2.3722e-02,  4.0867e-03, -6.5148e-02,  4.4365e-02,\n",
      "          4.6860e-02, -3.2517e-02,  4.0227e-03, -3.9760e-03,  1.1194e-02,\n",
      "         -9.9560e-02,  3.3317e-02,  8.0106e-02,  9.4269e-02, -6.3829e-02,\n",
      "          3.2315e-02, -5.1355e-02, -7.4987e-03,  5.3005e-34, -4.1320e-02,\n",
      "          9.4965e-02, -1.0640e-01,  4.9659e-02, -3.4191e-02, -3.1675e-02,\n",
      "         -1.7156e-02,  1.7010e-03,  5.7976e-02, -1.2177e-03, -1.6854e-02,\n",
      "         -5.1691e-02,  5.5300e-02, -3.4265e-02,  3.0818e-02, -3.1048e-02,\n",
      "          9.2753e-02,  3.7266e-02, -2.3740e-02,  4.4589e-02,  1.4615e-02,\n",
      "          1.1624e-01, -5.0011e-02,  3.8872e-02,  4.2474e-03,  2.5698e-02,\n",
      "          3.2724e-02,  4.2991e-02, -1.3614e-02,  2.5612e-02,  1.0626e-02,\n",
      "         -8.4686e-02, -9.5298e-02,  1.0840e-01, -7.5160e-02, -1.3777e-02,\n",
      "          6.3734e-02, -4.4967e-03, -3.2532e-02,  6.2361e-02,  3.4805e-02,\n",
      "         -3.5492e-02, -2.0022e-02,  3.6661e-02, -2.4884e-02,  1.0182e-02,\n",
      "         -7.0123e-02, -4.3195e-02,  2.9533e-02, -2.9488e-04, -3.4539e-02,\n",
      "          1.4668e-02, -9.8397e-02, -4.7049e-02, -8.8550e-03, -8.8991e-02,\n",
      "          3.5100e-02, -1.2960e-01, -4.9887e-02, -6.1205e-02, -5.9780e-02,\n",
      "          9.4632e-03,  4.9122e-02, -7.7503e-02,  8.0973e-02, -4.7926e-02,\n",
      "          2.3438e-03,  7.5703e-02, -2.4018e-02, -1.5255e-02,  4.8674e-02,\n",
      "         -3.8597e-02, -7.0483e-02, -1.2035e-02, -3.8879e-02, -7.7602e-02,\n",
      "         -1.0724e-02,  1.0419e-02, -2.1375e-02, -9.1739e-02, -1.1134e-02,\n",
      "         -2.9607e-02,  2.4646e-02,  4.6571e-03, -1.6345e-02, -3.9522e-02,\n",
      "          7.7337e-02, -2.8473e-02, -3.6994e-03,  8.2767e-02, -1.1041e-02,\n",
      "          3.1398e-02,  5.3509e-02,  5.7515e-02, -3.1762e-02, -1.5291e-08,\n",
      "         -7.9966e-02, -4.7680e-02, -8.5979e-02,  5.6962e-02, -4.0887e-02,\n",
      "          2.2383e-02, -4.6445e-03, -3.8013e-02, -3.1067e-02, -1.0728e-02,\n",
      "          1.9770e-02,  7.7700e-03, -6.0948e-03, -3.8638e-02,  2.8027e-02,\n",
      "          6.7814e-02, -2.3535e-02,  3.2175e-02,  8.0254e-03, -2.3911e-02,\n",
      "         -1.2200e-03,  3.1460e-02, -5.2492e-02, -8.0681e-03,  3.1477e-03,\n",
      "          5.1150e-02, -4.4410e-02,  6.3601e-02,  3.8508e-02,  3.3043e-02,\n",
      "         -4.1873e-03,  4.9559e-02, -5.6961e-02, -6.4971e-03, -2.4979e-02,\n",
      "         -1.6087e-02,  6.6229e-02, -2.0631e-02,  1.0805e-01,  1.6855e-02,\n",
      "          1.4381e-02, -1.3213e-02, -1.2939e-01,  6.9522e-02, -5.5577e-02,\n",
      "         -6.7541e-02, -5.4582e-03, -6.1360e-03,  3.9084e-02, -6.2878e-02,\n",
      "          3.7406e-02, -1.1657e-02,  1.2915e-02, -5.5250e-02,  5.1608e-02,\n",
      "         -4.3084e-03,  5.8025e-02,  1.8694e-02,  2.2781e-02,  3.2167e-02,\n",
      "          5.3798e-02,  7.0285e-02,  7.4931e-02, -8.4177e-02]])\n",
      "Original sentence: each sentence is converted\n"
     ]
    }
   ],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "cache_dir = 'MiniLM-L6'\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = f.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "# the sentence embeddings return a 2D dimentional array\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n",
    "\n",
    "# decoded_text  = tokenizer.decode(encoded_input['input_ids'][0], skip_special_tokens=True)\n",
    "# print(f\"Original sentence: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b35fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util \n",
    "\n",
    "def get_relevant_context(user_input:str, \n",
    "                         vault_embeddings:torch.tensor, \n",
    "                         vault_content:str, \n",
    "                         model:SentenceTransformer, \n",
    "                         top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieves the top-k most relevant context from the vault based on the user input.\n",
    "    \"\"\"\n",
    "    # First, we should return an empty array if nothing detected\n",
    "    if vault_embeddings.nelement() == 0: \n",
    "        return []\n",
    "    # Encode the user input\n",
    "    input_embedding = model.encode([user_input])\n",
    "    # Compute cosine similarity between the input and vault embeddings \n",
    "    cos_scores = util.cos_sim(input_embedding, vault_embeddings)[0] # Adjust top_k if it's greater than the number of available scores \n",
    "    print(cos_scores)\n",
    "    top_k = min(top_k, len(cos_scores))  # top_k here is just an interger\n",
    "    # Sort the scores and get the top-k indices\n",
    "    top_indices = torch.topk(cos_scores, k=top_k)[1].tolist()\n",
    "    print(top_indices)\n",
    "    # Get the corresponding context from the vault\n",
    "    relevant_context = [vault_content[idx].strip() for idx in top_indices]\n",
    "    return relevant_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3bf488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vault content: ['Ukraine could have had a worse night. No deal was cooked up without them.\\n', '\\n', 'US President Donald Trump looked upset and tired. Perhaps because Russian President Vladimir Putin appeared unbowed, still talking about the “root causes” of the war, and sounding unreformed. In what sounded like a threat, he even warned Kyiv and its European allies to not meddle in whatever ongoing process he believes he has dragged Trump into.\\n', '\\n', '“We expect that Kyiv and European capitals will perceive all this in a constructive manner and will not create any obstacles, will not make attempts to disrupt the emerging progress through provocations and behind-the-scenes intrigues,” Putin said.\\n', '\\n', 'Trump’s call to Kyiv and its NATO allies may present some sort of framework that Putin deemed an “agreement,” but ultimately in the look on Trump’s face and his words, it was clear he made no significant deal that he thinks will fly. The two didn’t even have lunch together and Putin raced out on his plane.\\n', '\\n', 'The hardest bits of negotiations are the bits that are left to be agreed at the end. And Trump’s statement that there were some “big” things left unsolved suggests little movement on issues like what land Putin wants and a ceasefire.\\n', '\\n', 'But there are two big wins here for Putin. First, the remarkable vision of a red carpet welcome to the United States and a ride in “the Beast” — which both present as an extraordinary form of reputational rehabilitation for an alleged war criminal. It was a horrific sight for many Ukrainians; soured further still by the Kremlin head calling Ukraine a “brotherly” nation, despite murdering its civilians for three and a half years.\\n', '\\n', 'The second win is time. Putin has bought more for his forces to advance across the frontline. It is unclear if Trump is sufficiently riled that secondary sanctions may follow in the days ahead. But Putin did not seem to behave as if he was in a hurry, suggesting further meetings and ongoing work. Time matters as Putin’s summer offensive is close to turning incremental gains into strategic wins.\\n', '\\n', 'In the end, Ukraine will wake up with its world unchanged. A ghastly world, but with no sudden US-Russian rapprochement or deal to try and swallow.']\n",
      "vault_embeddings_tensor: tensor([[ 0.0236,  0.0683, -0.0267,  ...,  0.0139, -0.0333, -0.0628],\n",
      "        [-0.1188,  0.0483, -0.0025,  ...,  0.1264,  0.0465, -0.0157],\n",
      "        [ 0.0470,  0.0366,  0.0751,  ..., -0.0468,  0.0151,  0.0365],\n",
      "        ...,\n",
      "        [ 0.0200, -0.0297,  0.0611,  ..., -0.0528,  0.0064, -0.0324],\n",
      "        [-0.1188,  0.0483, -0.0025,  ...,  0.1264,  0.0465, -0.0157],\n",
      "        [ 0.0170,  0.0483,  0.0124,  ..., -0.0754, -0.0252, -0.0707]])\n",
      "tensor([0.1115, 0.2034, 0.2421, 0.2034, 0.2038, 0.2034, 0.1658, 0.2034, 0.1805,\n",
      "        0.2034, 0.1899, 0.2034, 0.1987, 0.2034, 0.2895])\n",
      "[14, 2, 4, 1, 3]\n",
      "relevant_context: ['In the end, Ukraine will wake up with its world unchanged. A ghastly world, but with no sudden US-Russian rapprochement or deal to try and swallow.', 'US President Donald Trump looked upset and tired. Perhaps because Russian President Vladimir Putin appeared unbowed, still talking about the “root causes” of the war, and sounding unreformed. In what sounded like a threat, he even warned Kyiv and its European allies to not meddle in whatever ongoing process he believes he has dragged Trump into.', '“We expect that Kyiv and European capitals will perceive all this in a constructive manner and will not create any obstacles, will not make attempts to disrupt the emerging progress through provocations and behind-the-scenes intrigues,” Putin said.', '', '']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", \n",
    "                                      device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "user_input = \"What is the news today?\"\n",
    "vault_dir = \"temp-memory/vault2.txt\"\n",
    "vault_content = open(vault_dir, \"r\", encoding=\"utf-8\").readlines()\n",
    "print(f\"Vault content: {vault_content}\")\n",
    "vault_embeddings = embedding_model.encode(vault_content)\n",
    "vault_embeddings_tensor = torch.tensor(vault_embeddings)\n",
    "\n",
    "print(f\"vault_embeddings_tensor: {vault_embeddings_tensor}\")\n",
    "\n",
    "relevant_context = get_relevant_context(user_input=user_input, \n",
    "                                        vault_embeddings=vault_embeddings_tensor, \n",
    "                                        vault_content=vault_content,\n",
    "                                        model=embedding_model,\n",
    "                                        top_k=5)\n",
    "\n",
    "print(f'relevant_context: {relevant_context}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9fe11",
   "metadata": {},
   "source": [
    "***Now we test the LLM model***. We can run different models with different sizes, for example 6B, or larger like 20B, or 100B parameters. But everything must start with \"checking device\" first, choosing what models to run depends on the hardware configuration. Some PC only has CPU supported while others have strong GPU to run heavy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a city far away, there lived a princess. She was beautiful, and she was wise, and she was kind.\n",
      "\n",
      "She was also a little bit of a dork.\n",
      "\n",
      "The princess was Princess Leia.\n",
      "\n",
      "Princess Leia was born and raised on Tatooine, and she was a little bit of a nerd. She knew things. She read. She knew science. She knew history. She knew a little bit about the Force, too.\n",
      "\n",
      "She also had a crush on Luke Skywalker.\n",
      "\n",
      "The princess was Luke Skywalker.\n",
      "\n",
      "After a long day of playing with her friends, Princess Leia was sitting in her favorite chair, reading her favorite book, when something on her bookshelf caught her eye.\n",
      "\n",
      "She reached out and picked up her favorite book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She picked up the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page, she saw the title.\n",
      "\n",
      "She smiled. She was excited.\n",
      "\n",
      "She reached for the book.\n",
      "\n",
      "As she flipped to the next page,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n",
    "\n",
    "class LLM_Model:\n",
    "    def __init__(self, model_name, cache_dir, local_dir):\n",
    "        self.model_name = model_name\n",
    "        self.cache_dir = cache_dir\n",
    "        self.local_dir = local_dir\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.pretrained_model_and_tokenizer()\n",
    "    def pretrained_model_and_tokenizer(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.local_dir)\n",
    "        # # Initialize model with empty weights to manage device map efficiently\n",
    "        with init_empty_weights():\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(self.local_dir)\n",
    "            # tie the model weights to prevent memory overhead\n",
    "            self.model.tie_weights()\n",
    "\n",
    "        # Infer device map to manage model layers between GPU and CPU\n",
    "        device_map = infer_auto_device_map(self.model, max_memory={0: \"4GiB\", \"cpu\": \"6GiB\"})\n",
    "        # configure quantization using BitsAndBytesConfig\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            llm_int8_enable_fp32_cpu_offload=True,\n",
    "            load_in_8bit_fp32_cpu_offload=True\n",
    "        )\n",
    "\n",
    "        # Load the model with 8-bit quantization and mixed precision\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.local_dir,\n",
    "            device_map='auto',\n",
    "            quantization_config=quantization_config,\n",
    "            offload_folder=\"./offload\",\n",
    "            torch_dtype=torch.float16,\n",
    "            offload_state_dict=True\n",
    "        )\n",
    "\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "\n",
    "    def generate_text(self, prompt, max_length=500):\n",
    "        # Move inputs to the appropriate device (CPU or GPU)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        # Generate text using the optimized model\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=max_length,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        # Decode the outputs and return the generated text\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "model_name = \"facebook/opt-2.7B\"\n",
    "cache_dir = \"./optimized-opt-2.7B-8bit\"\n",
    "local_dir = \"./optimized-opt-2.7B-8bit/models--facebook--opt-2.7B/snapshots/905a4b602cda5c501f1b3a2650a4152680238254\"\n",
    "prompt = \"Once upon a time\"\n",
    "llm_model = LLM_Model(model_name=model_name, cache_dir=cache_dir, local_dir=local_dir)\n",
    "generated_text = llm_model.generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b75dc0",
   "metadata": {},
   "source": [
    "***Now we try to link the sentence embedding model with the LLM model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1060fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt_streamed(user_input, system_message, conversation_history, chatbot_name, vault_embeddings, vault_content,\n",
    "                     embed_model, top_k = 3):\n",
    "    \"\"\"\n",
    "    user_input: str\n",
    "    system_message: str (system instructions, role prompt)\n",
    "    conversation_history: list of dicts [{\"role\": \"user\"/\"assistant\", \"content\": str}]\n",
    "    chatbot_name: str\n",
    "    vault_embeddings: torch.Tensor of stored embeddings\n",
    "    vault_content: list of str\n",
    "    embed_model: SentenceTransformer instance\n",
    "    \"\"\"\n",
    "    relevant_context = get_relevant_context(user_input, vault_embeddings, vault_content, embed_model, top_k)\n",
    "    history_text = \"\\n\".join([f\"{msg['role'].capitalize()}: {msg['content']}\" for msg in conversation_history])\n",
    "    context_text = \"\\n\".join(relevant_context)\n",
    "    full_prompt = (\n",
    "        f\"{system_message}\\n\\n\"\n",
    "        f\"Relevant information from the knowledge vault:\\n{context_text}\\n\\n\"\n",
    "        f\"Conversation so far:\\n{history_text}\\n\\n\"\n",
    "        f\"User: {user_input}\\n{chatbot_name}:\"\n",
    "    )\n",
    "    generated_text = llm_model.generate_text(full_prompt)\n",
    "    if chatbot_name in generated_text:\n",
    "        output = generated_text.split(f\"{chatbot_name}:\")[-1].strip()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe6107d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m         conversation_history \u001b[38;5;241m=\u001b[39m conversation_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m:]\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(conversation_history, chatbot_response)\n\u001b[1;32m---> 72\u001b[0m \u001b[43muser_chatbot_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Start the conversation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m, in \u001b[0;36muser_chatbot_conversation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m vault_embeddings_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(vault_embeddings)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Clean up the temporary audio file\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43muser_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m: \u001b[38;5;66;03m# Say 'exit' to end the conversation break\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstartswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint info\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrint info\u001b[39m\u001b[38;5;124m\"\u001b[39m)): \u001b[38;5;66;03m# Print the contents of the vault.txt file \u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read()\n",
    "PINK = '\\033[95m'\n",
    "CYAN = '\\033[96m' \n",
    "YELLOW = '\\033[93m'\n",
    "NEON_GREEN = '\\033[92m'\n",
    "RESET_COLOR = '\\033[0m'\n",
    "import os\n",
    "chatbot_dir = 'temp-memory/chatbot2.txt'\n",
    "vault_dir = 'temp-memory/vault.txt'\n",
    "def user_chatbot_conversation():\n",
    "    conversation_history = []\n",
    "    system_message = open_file(chatbot_dir)\n",
    "    user_input = input(\"Input here: \")\n",
    "    sentence_embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    # Create embeddings for the initial vault content\n",
    "    vault_content = []\n",
    "    if os.path.exists(vault_dir):\n",
    "        with open(vault_dir, \"r\", encoding=\"utf-8\") as vault_file:\n",
    "            vault_content = vault_file.readlines()\n",
    "    vault_embeddings = sentence_embedding_model.encode(vault_content) if vault_content else []\n",
    "    vault_embeddings_tensor = torch.tensor(vault_embeddings)\n",
    "    while True:\n",
    "        # Clean up the temporary audio file\n",
    "        if user_input.lower() == \"exit\": # Say 'exit' to end the conversation break\n",
    "            break\n",
    "        elif user_input.lower().startswith((\"print info\", \"Print info\")): # Print the contents of the vault.txt file \n",
    "            print(\"Info contents:\")\n",
    "            if os.path.exists(vault_dir):\n",
    "                with open(vault_dir, \"r\", encoding=\"utf-8\") as vault_file: \n",
    "                    print(vault_file.read())\n",
    "            else:\n",
    "                print(\"Info is empty.\")\n",
    "            continue\n",
    "        elif user_input.lower().startswith((\"delete info\", \"Delete info\")): \n",
    "            confirm = input(\"Are you sure? Say 'Yes' to confirm: \")\n",
    "            if confirm.lower() == \"yes\":\n",
    "                if os.path.exists(vault_dir):\n",
    "                    os.remove(vault_dir)\n",
    "                    print(\"Info deleted.\") \n",
    "                    vault_content= []\n",
    "                    vault_embeddings = []\n",
    "                    vault_embeddings_tensor = torch.tensor(vault_embeddings)\n",
    "                else:\n",
    "                    print(\"Info is already empty.\")\n",
    "            else:\n",
    "                print(\"Info deletion cancelled.\")\n",
    "            continue\n",
    "        elif user_input.lower().startswith((\"insert info\", \"insert info\")): \n",
    "            with open(vault_dir, \"a\", encoding=\"utf-8\") as vault_file: \n",
    "                vault_file.write(user_input + \"\\n\")\n",
    "            print(\"Wrote to info.\")\n",
    "            # Update the vault content and embeddings\n",
    "            vault_content = open(vault_dir, \"r\", encoding=\"utf-8\").readlines()\n",
    "            vault_embeddings = sentence_embedding_model.encode(vault_content)\n",
    "            vault_embeddings_tensor = torch.tensor(vault_embeddings)\n",
    "        # continue\n",
    "    print(CYAN + \"You: \", user_input + RESET_COLOR)\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    print(PINK + \"Sarah: \"+ RESET_COLOR)\n",
    "    chatbot_response = chatgpt_streamed(user_input, system_message, conversation_history, \"Sarah\", vault_embeddings_tensor, vault_content, sentence_embedding_model) \n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": chatbot_response}) \n",
    "    # prompt2 = chatbot_response\n",
    "    # audio_file_pth2 = \"C:/Users/kris_/Python/fsts2/XTTS-v2/samples/emma2.wav\"\n",
    "    # process_and_play(prompt2, audio_file_pth2)\n",
    "    if len(conversation_history) > 20:\n",
    "        conversation_history = conversation_history[-20:]\n",
    "    print(conversation_history, chatbot_response)\n",
    "\n",
    "user_chatbot_conversation() # Start the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59703919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xtts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
